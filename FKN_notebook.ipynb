{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Demand for Cars with Inverse Product Differentiation Logit\n",
    "\n",
    "In this notebook, we will explore the dataset used in\n",
    "Brownstone and Train (1999). We will estimate the Inverse Product Differentiation Logit\n",
    "model using the FKN estimation routine given the available data using the functions defined below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from numpy import linalg as la\n",
    "from scipy import optimize\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools as iter\n",
    "\n",
    "# Files\n",
    "import Logit_file as logit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data\n",
    "====\n",
    "\n",
    "The data consists of a survey of households regarding their preferences\n",
    "for car purchase. Each household was given 6 options, but the\n",
    "characteristics that the respondents were asked about was varied. The\n",
    "surveys were originally conducted in order to illicit consumer\n",
    "preferences for alternative-fuel vehicles. The data is *stated\n",
    "preferences*, in the sense that consumers did not actually buy but just\n",
    "stated what they would hypothetically choose, which is of course a\n",
    "drawback. This is very common in marketing when historic data is either\n",
    "not available or does not provide satisfactory variation. The advantage\n",
    "of the stated preference data is therefore that the choice set can be\n",
    "varied greatly (for example, the characteristics includes the\n",
    "availability of recharging stations, which is important for purchase of\n",
    "electric cars).\n",
    "\n",
    "The data has $N=4654$ respondents with $J=6$ cars to choose\n",
    "from.\n",
    "\n",
    "Loading the dataset, `car_data.csv`, we get a dataframe with \n",
    "$NJ = 27,924$ rows. The column `person_id` runs through $0,1,...,N-1$, and\n",
    "the column `j` is the index for the car, $\\{0,1,...,5\\}$. The variable \n",
    "`binary_choice` is a dummy, =1 for the car chosen by the respondent. \n",
    "A conveneint other variable, `y`, is the index for that car, repeated \n",
    "and identical for all $J$ rows for each person. The x-variables describe \n",
    "the characteristics of the 6 cars that the respondent was asked to choose \n",
    "from. \n",
    "\n",
    "We also read in the dataset `car_labels.csv`, which contains the \n",
    "variable labels and descriptions for all the variables. \n",
    "The list `x_vars` will be used throughout as the list of \n",
    "explanatory variables we want to work with. \n",
    "\n",
    "In order to get the data into a 3-dimensional array, we access \n",
    "the underlying numpy arrays and resize them. For example \n",
    "\n",
    "> `x = dat[x_vars].values.resize((N,J,K))`\n",
    "\n",
    "Note that this will only work because the data is sorted according to \n",
    "first `person_id` and then `j`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and variable names\n",
    "input_path = os.getcwd() # Assigns input path as current working directory (cwd)\n",
    "dat = pd.read_csv(os.path.join(input_path, 'car_data.csv'))\n",
    "lab = pd.read_csv(os.path.join(input_path, 'car_labels.csv'), index_col = 'variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image('brownstone_train_tab_1.PNG')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1 from 'Forecasting new product penetration with flexible substitution patterns (1999), D. Brownstone, K. Train'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling variables\n",
    "\n",
    "To be consistent with the interpretation of estimates in 'Brownstone & Train (1999)' we rescale some of the explanatory variables. Furthermore, Logit models are most stable numerically if we ensure that variables are scaled near to $\\pm 1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['range'] = dat['range'] / 100                  # Hundreds of miles that the vehicle can travel between fuelings\n",
    "dat['top_speed'] = dat['top_speed'] / 100          # Highest speed that the vehicle can attain, in hundreds of miles per hour\n",
    "dat['size'] = dat['size'] / 10                     # Scaled categorical variable for numerical purposes\n",
    "dat['acceleration'] = dat['acceleration'] / 10     # Measured in tens of seconds\n",
    "dat['operating_cost'] = dat['operating_cost'] / 10 # Measured in tens of cents per mile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, respectively, 'EV' and'Non-EV' and also 'CNG' and 'Non-CNG' are equivalent we exclude the latter and keep all the other characteristics as explanatory variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to use as explanatory variables\n",
    "x_vars = list(lab.iloc[3:-4].index.values) # variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of data\n",
    "N = dat.person_id.nunique()\n",
    "J = dat.j.nunique()\n",
    "K = len(x_vars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will primarily use numpy data types and numpy functions in this notebook. Hence we store our response variable 'y' and our explanatory variables 'x' as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response and explanatory variables as numpy arrays\n",
    "a = dat['y'].values.reshape((N,J))\n",
    "a = a[:, 0] # All values are equal along axis=1. Becomes an (N,) array i.e. it is a vector.\n",
    "y = pd.get_dummies(a).to_numpy() # Convert y to an (N,J) array as the onehot encoding\n",
    "x = dat[x_vars].values.reshape((N,J,K))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPDL Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nests of cars\n",
    "In our case, we construct nests along the dimensions of 'Fuel Type' and 'Body Type' as suggested by the figure below. Each alternative is assigned to two nests: One representing fuel type (Electric, Combustion/Natural Gas , Methanol) and one representing body type (Car, Truck/Van)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display.Image('brownstone_train_fig_1.gif')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1 from 'Forecasting new product penetration with flexible substitution patterns (1999), D. Brownstone, K. Train'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The IPDL model - Nesting structure\n",
    "\n",
    "The IPDL model is a generalization of the nested logit model where each alternative may belong to more than one nest. Before fully introducing the model, we construct the nesting structure.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing nests\n",
    "\n",
    "Let $\\Delta=\\left\\{q\\in \\mathbb{R}^J_+: \\sum_{j=1}^J q_j=1\\right\\}$ denote the probability simplex. For each group of nests $g=1,\\ldots, G$, nest membership is denoted by the matrix $\\Psi^g\\in \\mathbb R^{C_g\\times J}$: $\\Psi^g_{cj}=1$ if product $j$ belongs to nest $c$ and zero otherwise, and each product can only belong to one nest within each group, meaning that $\\sum_{c=1}^{C_g}\\Psi^g_{cj}=1$ for all $j$ and all $g$. The matrix-vector product $\\Psi^gq$ is then\n",
    "$$\n",
    "\\Psi^g q=\\sum_j \\Psi^{g}_{cj}q_j=\\left(\\begin{array}{c}\n",
    "\\sum_{j:\\Psi^g_{1j}=1} q_j \\\\\n",
    "\\vdots \\\\\n",
    "\\sum_{j: \\Psi^g_{C_gj}=1}q_j\n",
    "\\end{array}\\right),\n",
    "$$\n",
    "and the vector $\\Psi^gq$ is a vector of nest-specific choice probabilities, i.e. the sum of the probabilities within each nest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The perturbation function $\\Omega$\n",
    "\n",
    "In the following, a vector $z\\in \\mathbb R^d$ is always a column vector. We now construct the IPDL perturbation function which has the form (where for a vector $z$, the logarithm is applied elementwise and $z'$ denote the transpose)\n",
    "$$\n",
    "\\Omega(q|\\lambda)= (1-\\sum_{g=1}^G \\lambda_g) q'\\ln q +\\sum_{g=1}^{G} \\lambda_g \\left(\\Psi^g q \\right)'\\ln \\left(\\Psi^g q\\right).\n",
    "$$\n",
    "Note that since $\\Psi^g q$ denotes a probability distribution over the nests, the term $(\\Psi^gq)'\\ln (\\Psi^gq)$ is the (negative) entropy of the probability distribution $\\Psi^g q$. Note also that as each nest has at least one member, and $q$ is strictly positive, $\\Psi^gq$ is also strictly positive. When the parameters $\\lambda_g$ satisfy $\\lambda_g>0$ and\n",
    "$$\n",
    "\\sum_g \\lambda_g<1,\n",
    "$$\n",
    "the function $\\Omega(\\cdot|\\lambda)$ is a strictly convex function of $q$, and the utility maximization problem has a unique interior (meaning strictly positive choice probabilities) solution. When there is only one group of nests, $G=1$, then $\\Omega$ induces the nested logit choice probabilities (note though that the nested logit model is often parameterized in terms of the nesting parameter $\\mu=1-\\lambda$ instead!). \n",
    "\n",
    "It will be convenient to define a choice probability function for a given vector of payoffs $u$ as\n",
    "$$\n",
    "P(u|\\lambda)=\\arg \\max_{q\\in \\Delta}q'u-\\Omega(q|\\lambda).\n",
    "$$\n",
    "Letting $\\theta$ denote the full vector of parameters, $\\theta=(\\beta',\\lambda')'$, the individual choice probabilities is a function of the matrix $\\mathbf{X}_i$ and the parameters $\\theta$, as\n",
    "$$\n",
    "p(\\mathbf{X}_i,\\theta)=\\arg\\max_{q\\in \\Delta}q'\\mathbf{X}_i \\beta-(1-\\sum_{g=1}^G\\lambda_g)q'\\ln q-\\sum_{g=1}^G\\lambda_g \\left(\\Psi^g q \\right)'\\ln \\left(\\Psi^g q\\right)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
